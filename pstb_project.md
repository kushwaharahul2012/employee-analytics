# PSTB Project Log (Python + SQL + Tableau + Bash)

This file tracks the 30-day PSTB Challenge in an integrated, advanced format.  
Each day touches all 4 stacks (Python, SQL, Tableau, Bash).

---

## Day 1/30 â€“ Project Setup & Raw Data Load

### âœ… Python
- Wrote ingestion script to read raw HR CSV.

### âœ… SQL
- Created database `employeeanalytics`.
- Created table `[dbo].[employees_raw]`.
- Loaded raw CSV data into `employees_raw`.

### âœ… Tableau
- Connected Tableau to the database (test connection only).

### âœ… Bash
- Added `ingest.sh` to automate raw data load into SQL.

ðŸŽ¯ Why this matters: Establishes the raw â†’ DB â†’ viz pipeline foundation.

---

## Day 2/30 â€“ SQL Exploration & Basic Queries

### âœ… Python
- Verified ingestion script, exported sample data for quick inspection.

### âœ… SQL
- Ran basic queries on `employees_raw`: filtering, grouping, counts.
- Identified missing values and duplicate records.

### âœ… Tableau
- First draft viz (simple employee headcount by department).

### âœ… Bash
- Updated `ingest.sh` with logs.

ðŸŽ¯ Why this matters: Early insight into data issues before cleaning.

---

## Day 3/30 â€“ Data Cleaning Prep

### âœ… Python
- Draft cleaning logic (remove nulls, handle duplicates, fix types).
- Created reusable cleaning functions.

### âœ… SQL
- Created test table for cleaned inserts.

### âœ… Tableau
- Verified which columns are needed for dashboards.

### âœ… Bash
- Added cleaning step stub into pipeline.

ðŸŽ¯ Why this matters: Prepares the ETL logic before building a stable clean dataset.

---

## Day 4/30 â€“ Data Wrangling Day ðŸ§¹ðŸ“Š

### âœ… Python
- Completed cleaning script.
- Handled nulls, standardized formats, dropped duplicates.
- Output: clean DataFrame ready for SQL.

### âœ… SQL
- Created `[dbo].[employees_clean]`.
- Loaded cleaned data into `employees_clean`.

### âœ… Tableau
- Exported clean CSV for Tableau Public.
- Built distribution chart (employees by department).

### âœ… Bash
- Pipeline (`pipeline.sh`) now runs: raw â†’ clean â†’ SQL load â†’ CSV export.

ðŸŽ¯ Why this matters: Clean data = reliable dashboards. Full pipeline automated.

---

## Day 5/30 â€“ Normalize employees/salaries/performance tables

### âœ… Python
- Extended cleaning script to split data into employees, salaries, performance DataFrames.
- Prepared departments lookup DataFrame.

### âœ… SQL
- Created normalized tables: `employees`, `salaries`, `performance`, `departments` inside `employeeanalytics`.
- Populated them automatically from Python (INSERT via pyodbc/SQLAlchemy).

### âœ… Tableau
- Connected Tableau to normalized schema.
- Tested quick viz: salary vs KPI by department (JOIN across tables).

### âœ… Bash
- Updated pipeline: after cleaning, normalization step runs automatically.
- One command now loads both `employees_clean` and normalized tables.

ðŸŽ¯ Why this matters: Moves from flat data to relational design. Enables deeper analysis and richer Tableau dashboards.

---
